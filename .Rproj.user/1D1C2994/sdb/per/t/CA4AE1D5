{
    "collab_server" : "",
    "contents" : "#################################################\n####POLITICAL TARGETING ON TWITTER - A BRIEF STUDY#####\n################# Paul Le Ster ##################\n#################################################\n#The purpose of this code is to understand how Trump's tweeting strategy changed throughout his campaign\n#Hypothesis 1: Trump switches his focus from republicans to democrats once he becomes the nominee\n#Hypothesis 2: Trump tweet mentions of his political opponents will drop drastically as they drop out of the race\n\nlibrary(ggplot2)\nlibrary(stringr)\nlibrary(lubridate)\nlibrary(scales)\nlibrary(tidytext)\nlibrary(tidyr)\nlibrary(ggthemes)\nlibrary(extrafont)\nlibrary(splitstackshape)\nlibrary(dplyr)\n\n#note weird bug when plyr loaded last\n#http://stackoverflow.com/questions/26923862/why-are-my-dplyr-group-by-summarize-not-working-properly-name-collision-with\n\nsource(\"twitterTargetHelp.R\")\n\n################################\n#GET RAW TWEETS\n#Tweets are from Trump twitter archive\n#Pulled by copy and pasting into csv <- TODO: do through web scraping next time\n#################################\n\n#Try for all tweets\ntweets.raw <- read.csv(\"rawtweets.csv\", header = FALSE, as.is=TRUE)\ntweets.df <- data.frame(tweets.raw)\n\n#initial split\ntweets.df<-cSplit(tweets.df, 'V1', sep=\"\\xca\", type.convert=FALSE)\nkeeps <- c(\"V1_1\", \"V1_2\",\"V1_3\")\ntweets.df = subset(tweets.df, select = -c(V1_4,V1_5,V1_6) )\n\n#Hacky Date fix\ntweets.df$dateraw = substr(tweets.df$V1_1,1,nchar(tweets.df$V1_1)-12)\ntweets.df$dateraw = trimws(tweets.df$dateraw)\ntweets.df$month = substr(tweets.df$dateraw,1,3)\ntweets.df$day = substr(tweets.df$dateraw,5,6)\ntweets.df$day = gsub(',','',tweets.df$day)\ntweets.df$year = substr(tweets.df$V1_1,nchar(tweets.df$dateraw)-3,nchar(tweets.df$dateraw))\ntweets.df$date <- as.Date(paste(tweets.df$day,tweets.df$month,tweets.df$year, sep=\"\"), \"%d%b%Y\")\ntweets.df = subset(tweets.df, select = -c(V1_1,day,month,year,dateraw) )\n\n###########################\n##Clean text data\n##########################\n\n#remove tweets startign with \" -> indication of a manual retweet\ncolnames(tweets.df)[1] <- \"text\"\nreg <- \"([^A-Za-z\\\\d#@']|'(?![A-Za-z\\\\d#@]))\"\ntweet.words <- tweets.df %>%\n  filter(!str_detect(text, '^\"')) %>%\n  mutate(text = str_replace_all(text, \"https://t.co/[A-Za-z\\\\d]+|&amp;\", \"\")) %>%\n  unnest_tokens(word, text, token = \"regex\", pattern = reg) %>%\n  filter(!word %in% stop_words$word,\n         str_detect(word, \"[a-z]\"))\n\n\n\n\n###########################\n##Tweets by Party\n##########################\n\nparty <- NULL\nfor(i in 1:nrow(tweet.words)) {\n  party <- c(party,extractParty(tweet.words[i,\"word\"]))\n}\n\ntweet.words$party= party\ntweet.party.only <- tweet.words[which(!str_detect(tweet.words$party, \"No target\")),]\n\n#extract target frequency BY DAY\nparty.by.days= as.data.frame(table(tweet.party.only$party, tweet.party.only$date))\ncolnames(party.by.days) <- c(\"party\",\"date\", \"freq\")\nparty.by.days$date <- as.Date(party.by.days$date)\n\n#Plot 1 - freqency of mentions vs date\np1 <- ggplot() + geom_line(aes(date, freq, color=party), party.by.days)\np1\n#Looks like plots needs to go by week to get cleaner lines\n\n#BY WEEK\n#note: hacky fix to enumerate weeks after >1 year\ntweet.party.only$week = week(tweet.party.only$date)+(53*(year(tweet.party.only$date)-2015))\n\nparty.by.week = as.data.frame(table(tweet.party.only$party, tweet.party.only$week))\ncolnames(party.by.week) <- c(\"party\",\"week\", \"freq\")\nparty.by.week.percentage<- party.by.week %>% group_by(week) %>% mutate(percentage = freq/sum(freq))\n\n#note this is to allow for geom_Area to map\nparty.by.week.percentage$week2 = as.integer(party.by.week.percentage$week)\n\n\nPalette1 <- c('green','blue')\n\n#ATTEMPTING TO FIX ORDER\nparty.by.week.percentage$party2 <- factor(party.by.week.percentage$party, levels=c(\"Republican\",\"Democrat\"))\nparty.by.week.percentage$party2 <- factor(party.by.week.percentage$party, levels=rev(levels(party.by.week.percentage$party)))\n\n\n\n\n\np4 <- ggplot() + geom_area(aes(y=percentage, x=week2, fill=party2), party.by.week.percentage, \n                           stat=\"identity\") + ylab(\"percentage of tweets\") + xlab(\"week # since Jan\")\n\n\np4 \n\n\n\nPalette2 <- c('indianred1','dodgerblue2')\n\n\np4 + scale_x_continuous(breaks=seq(3,72,4),labels=c(\"Jul15\", \"Aug15\", \"Sep15\", \"Oct15\", \"Nov15\", \"Dec15\", \"Jan16\", \"Feb16\", \"Mar16\", \"Apr16\", \"May16\", \"Jun16\", \"Jul16\", \"Jul16\", \"Aug16\", \"Sep16\", \"Oct16\",\"Nov16\")) + scale_y_continuous(labels = percent) + scale_fill_manual(values = Palette2)\n\n\n\n\n###########################\n##Tweets by individual\n##########################\n\n\n#IDENTIFYING INDIVIDUAL TARGETS\n#Approach is basic: simply identifying when they are mentioned in a tweet\n#Weakness: sometimes tweets may be directed at the person, but without mentioning them by name\n#Note: ignoring obama for now, because wanted to focus on his direct opponents\n\ntargets <- NULL\nfor(i in 1:nrow(tweet.words)) {\n  targets <- c(targets,extractTarget(tweet.words[i,\"word\"]))\n}\ntweet.words$target= targets\n\n#Filter out the \"no targets\"\ntweet.targets.only <- tweet.words[which(!str_detect(tweet.words$target, \"No target\")),]\n\n#extract target frequency BY DAY\ntargets.by.day= as.data.frame(table(tweet.targets.only$target, tweet.targets.only$date))\ncolnames(targets.by.day) <- c(\"target\",\"date\", \"freq\")\ntargets.by.day$date <- as.Date(targets.by.day$date)\n\n#Plot 0 - freqency of mentions vs date\np0 <- ggplot() + geom_line(aes(date, freq, color=target), targets.by.day)\np0\n#Looks like plots needs to go by week to get cleaner lines\n\n#BY WEEK\n#note: hacky fix to enumerate weeks after >1 year\ntweet.targets.only$week = week(tweet.targets.only$date)+(53*(year(tweet.targets.only$date)-2015))\ntargets.by.week = as.data.frame(table(tweet.targets.only$target, tweet.targets.only$week))\ncolnames(targets.by.week) <- c(\"target\",\"week\", \"freq\")\n\ntargets.by.week.percentage<- targets.by.week %>% group_by(week) %>% mutate(percentage = freq/sum(freq))\n\n#note this is to allow for geom_Area to map\ntargets.by.week.percentage$week2 = as.integer(targets.by.week.percentage$week)\n\n\ntargetstest <- reorderTargets(targets.by.week.percentage)\n\n\n\np2 <- ggplot() + geom_area(aes(y=percentage, x=week2, fill=target), targetstest, \n                           stat=\"identity\") + ylab(\"percentage of tweets\") + xlab(\"date\")\n\nPalette1 <- c('lightpink','darkslategray1','dodgerblue2','lightskyblue4', 'maroon1','hotpink4','indianred1')\n\np2 + scale_x_continuous(breaks=seq(3,72,4), \n                        labels=c(\"Jul15\", \"Aug15\", \"Sep15\", \"Oct15\", \"Nov15\", \"Dec15\", \"Jan16\", \"Feb16\", \"Mar16\", \"Apr16\", \"May16\", \"Jun16\", \"Jul16\", \"Jul16\", \"Aug16\", \"Sep16\", \"Oct16\",\"Nov16\"))+ \n  scale_y_continuous(labels = percent)\n\n\n\n\n",
    "created" : 1485966231313.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4113021176",
    "id" : "CA4AE1D5",
    "lastKnownWriteTime" : 1485968586,
    "last_content_update" : 1485968586737,
    "path" : "~/datascience/twitter_targeting/twitterTargeting.R",
    "project_path" : "twitterTargeting.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}